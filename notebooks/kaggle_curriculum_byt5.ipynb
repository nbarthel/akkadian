{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Past Challenge - Curriculum ByT5 Training\n",
    "\n",
    "**Model**: google/byt5-small (300M params, byte-level tokenization)\n",
    "**Data**: 161K assembled Akkadian-English pairs\n",
    "**Strategy**: 2-phase curriculum learning\n",
    "- Phase 1: All gold-quality pairs (~126K) — general Akkadian\n",
    "- Phase 2: Old Assyrian dialect only (~15K) — competition domain\n",
    "\n",
    "**Metric**: √(BLEU × chrF++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from datasets import Dataset as HFDataset\n",
    "from sacrebleu.metrics import BLEU, CHRF\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "ASSEMBLED_DIR = Path('/kaggle/input/akkadian-assembled-161k')\n",
    "COMPETITION_DIR = Path('/kaggle/input/deep-past-initiative-machine-translation')\n",
    "OUTPUT_DIR = Path('/kaggle/working')\n",
    "\n",
    "# Model\n",
    "MODEL_NAME = 'google/byt5-small'\n",
    "PREFIX = 'translate Akkadian to English: '\n",
    "\n",
    "# Sequence lengths (ByT5 byte-level)\n",
    "MAX_SOURCE_LENGTH = 512\n",
    "MAX_TARGET_LENGTH = 256\n",
    "\n",
    "# Phase 1: General Akkadian (all gold data)\n",
    "P1_EPOCHS = 5\n",
    "P1_BATCH_SIZE = 16\n",
    "P1_GRAD_ACCUM = 2\n",
    "P1_LR = 5e-5\n",
    "P1_WARMUP = 0.1\n",
    "\n",
    "# Phase 2: Old Assyrian specialization\n",
    "P2_EPOCHS = 10\n",
    "P2_BATCH_SIZE = 8\n",
    "P2_GRAD_ACCUM = 4\n",
    "P2_LR = 1e-5\n",
    "P2_WARMUP = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembled dataset\n",
    "train_df = pd.read_parquet(ASSEMBLED_DIR / 'train.parquet')\n",
    "val_df = pd.read_parquet(ASSEMBLED_DIR / 'val.parquet')\n",
    "comp_df = pd.read_parquet(ASSEMBLED_DIR / 'val_competition.parquet')\n",
    "\n",
    "# Competition test set\n",
    "test_df = pd.read_csv(COMPETITION_DIR / 'test.csv')\n",
    "\n",
    "print(f\"Full train: {len(train_df)}\")\n",
    "print(f\"Val: {len(val_df)}\")\n",
    "print(f\"Competition val: {len(comp_df)}\")\n",
    "print(f\"Test: {len(test_df)}\")\n",
    "print(f\"\\nDialects: {train_df['dialect'].value_counts().to_dict()}\")\n",
    "print(f\"Quality: {train_df['quality'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, tokenizer, prefix, max_source_length, max_target_length):\n",
    "    \"\"\"Tokenize inputs and targets with separate max lengths.\"\"\"\n",
    "    inputs = [prefix + str(text) for text in examples['transliteration']]\n",
    "    targets = [str(text) for text in examples['translation']]\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, truncation=True)\n",
    "    labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def score_predictions(predictions, references, prefix=\"\"):\n",
    "    \"\"\"Compute BLEU, chrF++, and geo_mean.\"\"\"\n",
    "    bleu = BLEU()\n",
    "    chrf = CHRF(word_order=2)\n",
    "    bleu_score = bleu.corpus_score(predictions, [references]).score\n",
    "    chrf_score = chrf.corpus_score(predictions, [references]).score\n",
    "    geo_mean = np.sqrt(max(bleu_score, 0) * max(chrf_score, 0))\n",
    "    p = f\"{prefix}_\" if prefix else \"\"\n",
    "    return {f\"{p}bleu\": bleu_score, f\"{p}chrf\": chrf_score, f\"{p}geo_mean\": geo_mean}\n",
    "\n",
    "\n",
    "def create_compute_metrics(tokenizer):\n",
    "    \"\"\"Create metrics computation function for Trainer.\"\"\"\n",
    "    bleu = BLEU()\n",
    "    chrf = CHRF(word_order=2)\n",
    "\n",
    "    def compute_metrics(predictions_and_labels):\n",
    "        preds, labels = predictions_and_labels\n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        b = bleu.corpus_score(decoded_preds, [decoded_labels]).score\n",
    "        c = chrf.corpus_score(decoded_preds, [decoded_labels]).score\n",
    "        return {'bleu': b, 'chrf': c, 'geo_mean': np.sqrt(max(b, 0) * max(c, 0))}\n",
    "\n",
    "    return compute_metrics\n",
    "\n",
    "\n",
    "class FullValCallback(TrainerCallback):\n",
    "    \"\"\"Score predictions on the full validation set after each eval.\"\"\"\n",
    "    def __init__(self, trainer, full_val_dataset, full_val_refs, tokenizer):\n",
    "        self.trainer = trainer\n",
    "        self.full_val_dataset = full_val_dataset\n",
    "        self.full_val_refs = full_val_refs\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        preds = self.trainer.predict(self.full_val_dataset)\n",
    "        decoded = self.tokenizer.batch_decode(preds.predictions, skip_special_tokens=True)\n",
    "        metrics = score_predictions(decoded, self.full_val_refs, prefix=\"full_val\")\n",
    "        for k, v in metrics.items():\n",
    "            print(f\"  {k}: {v:.4f}\")\n",
    "        state.log_history[-1].update(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_phase(phase, train_data_df, comp_data_df, val_data_df,\n",
    "              model_path, epochs, batch_size, grad_accum, lr, warmup,\n",
    "              tokenizer_obj=None):\n",
    "    \"\"\"Run a single training phase. Returns (model, tokenizer, best_dir, metrics).\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PHASE {phase}: {'General Akkadian' if phase == 1 else 'Old Assyrian Specialization'}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    checkpoint_dir = OUTPUT_DIR / f'phase{phase}_checkpoints'\n",
    "    best_dir = OUTPUT_DIR / f'phase{phase}_best'\n",
    "\n",
    "    # Load model\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    tokenizer = tokenizer_obj or AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "    model.to(device)\n",
    "    print(f\"Parameters: {model.num_parameters():,}\")\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_data = train_data_df[['transliteration', 'translation']].reset_index(drop=True)\n",
    "    comp_data = comp_data_df[['transliteration', 'translation']].reset_index(drop=True)\n",
    "    full_val_data = val_data_df[['transliteration', 'translation']].reset_index(drop=True)\n",
    "    full_val_refs = full_val_data['translation'].tolist()\n",
    "\n",
    "    print(f\"Train: {len(train_data)}, Eval (competition): {len(comp_data)}, Full val: {len(full_val_data)}\")\n",
    "\n",
    "    train_dataset = HFDataset.from_pandas(train_data)\n",
    "    eval_dataset = HFDataset.from_pandas(comp_data)\n",
    "    full_val_dataset = HFDataset.from_pandas(full_val_data)\n",
    "\n",
    "    # Tokenize\n",
    "    preprocess_fn = lambda x: preprocess_function(\n",
    "        x, tokenizer, PREFIX, MAX_SOURCE_LENGTH, MAX_TARGET_LENGTH\n",
    "    )\n",
    "    remove_cols = ['transliteration', 'translation']\n",
    "    train_dataset = train_dataset.map(preprocess_fn, batched=True, remove_columns=remove_cols)\n",
    "    eval_dataset = eval_dataset.map(preprocess_fn, batched=True, remove_columns=remove_cols)\n",
    "    full_val_dataset = full_val_dataset.map(preprocess_fn, batched=True, remove_columns=remove_cols)\n",
    "\n",
    "    # Training args\n",
    "    gen_max_length = max(MAX_SOURCE_LENGTH, MAX_TARGET_LENGTH)\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=str(checkpoint_dir),\n",
    "        save_strategy='epoch',\n",
    "        eval_strategy='epoch',\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=grad_accum,\n",
    "        num_train_epochs=epochs,\n",
    "        warmup_ratio=warmup,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=50,\n",
    "        predict_with_generate=True,\n",
    "        generation_max_length=gen_max_length,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='geo_mean',\n",
    "        greater_is_better=True,\n",
    "        save_total_limit=2,\n",
    "        report_to='none',\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer=tokenizer, model=model, padding=True, label_pad_token_id=-100\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=create_compute_metrics(tokenizer),\n",
    "        processing_class=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.add_callback(FullValCallback(trainer, full_val_dataset, full_val_refs, tokenizer))\n",
    "\n",
    "    # Train\n",
    "    print(\"\\nStarting training...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # Final eval\n",
    "    print(\"\\nFinal validation...\")\n",
    "    results = trainer.evaluate()\n",
    "    print(\"Competition val results:\")\n",
    "    for k, v in results.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "    # Save best\n",
    "    model.save_pretrained(best_dir)\n",
    "    tokenizer.save_pretrained(best_dir)\n",
    "    print(f\"Best model saved to: {best_dir}\")\n",
    "\n",
    "    # Cleanup checkpoints to save disk\n",
    "    import shutil\n",
    "    if checkpoint_dir.exists():\n",
    "        shutil.rmtree(checkpoint_dir)\n",
    "        print(f\"Cleaned up checkpoints: {checkpoint_dir}\")\n",
    "\n",
    "    return model, tokenizer, best_dir, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: General Akkadian (all gold data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Phase 1: gold quality only\n",
    "p1_train = train_df[train_df['quality'] == 'gold'].reset_index(drop=True)\n",
    "print(f\"Phase 1 training samples: {len(p1_train)}\")\n",
    "\n",
    "model_p1, tokenizer_p1, p1_best_dir, p1_results = run_phase(\n",
    "    phase=1,\n",
    "    train_data_df=p1_train,\n",
    "    comp_data_df=comp_df,\n",
    "    val_data_df=val_df,\n",
    "    model_path=MODEL_NAME,\n",
    "    epochs=P1_EPOCHS,\n",
    "    batch_size=P1_BATCH_SIZE,\n",
    "    grad_accum=P1_GRAD_ACCUM,\n",
    "    lr=P1_LR,\n",
    "    warmup=P1_WARMUP,\n",
    ")\n",
    "\n",
    "# Free memory\n",
    "del model_p1\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Old Assyrian Specialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Phase 2: Old Assyrian dialect\n",
    "p2_train = train_df[train_df['dialect'] == 'old_assyrian'].reset_index(drop=True)\n",
    "print(f\"Phase 2 training samples: {len(p2_train)}\")\n",
    "\n",
    "model_p2, tokenizer_p2, p2_best_dir, p2_results = run_phase(\n",
    "    phase=2,\n",
    "    train_data_df=p2_train,\n",
    "    comp_data_df=comp_df,\n",
    "    val_data_df=val_df,\n",
    "    model_path=str(p1_best_dir),  # Resume from Phase 1\n",
    "    epochs=P2_EPOCHS,\n",
    "    batch_size=P2_BATCH_SIZE,\n",
    "    grad_accum=P2_GRAD_ACCUM,\n",
    "    lr=P2_LR,\n",
    "    warmup=P2_WARMUP,\n",
    ")\n",
    "\n",
    "# Clean up Phase 1 model to save disk\n",
    "import shutil\n",
    "if p1_best_dir.exists():\n",
    "    shutil.rmtree(p1_best_dir)\n",
    "    print(f\"Cleaned up Phase 1 model: {p1_best_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions & Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test predictions with the Phase 2 model\n",
    "print(\"Generating test predictions...\")\n",
    "\n",
    "test_inputs = [PREFIX + str(t) for t in test_df['transliteration']]\n",
    "test_enc = tokenizer_p2(\n",
    "    test_inputs,\n",
    "    max_length=MAX_SOURCE_LENGTH,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='pt'\n",
    ").to(device)\n",
    "\n",
    "model_p2.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model_p2.generate(\n",
    "        input_ids=test_enc['input_ids'],\n",
    "        attention_mask=test_enc['attention_mask'],\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "    )\n",
    "\n",
    "predictions = tokenizer_p2.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "print(\"\\nPredictions:\")\n",
    "for i, (src, pred) in enumerate(zip(test_df['transliteration'], predictions)):\n",
    "    print(f\"\\n=== Sample {i} ===\")\n",
    "    print(f\"Source: {src[:120]}...\")\n",
    "    print(f\"Translation: {pred[:300]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({'id': test_df['id'], 'translation': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission saved!\")\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Phase 1 — competition geo_mean: {p1_results.get('eval_geo_mean', 'N/A'):.4f}\")\n",
    "print(f\"Phase 2 — competition geo_mean: {p2_results.get('eval_geo_mean', 'N/A'):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 0,
     "sourceId": 0,
     "sourceType": "competition",
     "sourceSlug": "deep-past-initiative-machine-translation"
    },
    {
     "datasetId": 0,
     "sourceId": 0,
     "sourceType": "datasetVersion",
     "sourceSlug": "nicbarthelemy1/akkadian-assembled-161k"
    }
   ],
   "dockerImageVersionId": 0,
   "isInternetEnabled": true,
   "language": "python",
   "isGpuEnabled": true,
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
