{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: NLLB Teacher — Generate Translations\n",
    "\n",
    "Runs `phucthaiv02/akkadian-nllb-2` (3.3B, Akkadian-adapted NLLB) on all training transliterations.\n",
    "Saves gold + NLLB translations as parquet for use by the ByT5 training notebook.\n",
    "\n",
    "**Output:** `/kaggle/working/gold_with_nllb.parquet`, `/kaggle/working/test_nllb_predictions.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, gc, math, time, warnings\nfrom pathlib import Path\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom sacrebleu.metrics import BLEU, CHRF\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Device: {device}')\nif torch.cuda.is_available():\n    print(f'GPU: {torch.cuda.get_device_name(0)}')\n    print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file(filename, base='/kaggle/input'):\n",
    "    for root, dirs, files in os.walk(base):\n",
    "        if filename in files:\n",
    "            return Path(root)\n",
    "    return None\n",
    "\n",
    "# Show input layout for debugging\n",
    "print('Contents of /kaggle/input/')\n",
    "for d in sorted(os.listdir('/kaggle/input')):\n",
    "    full = os.path.join('/kaggle/input', d)\n",
    "    if os.path.isdir(full):\n",
    "        print(f'  {d}/')\n",
    "        for f in sorted(os.listdir(full))[:15]:\n",
    "            print(f'    {f}')\n",
    "\n",
    "DATA_DIR = find_file('train.parquet')\n",
    "if DATA_DIR is None:\n",
    "    raise FileNotFoundError('Cannot find train.parquet under /kaggle/input/')\n",
    "print(f'\\nAssembled data at: {DATA_DIR}')\n",
    "\n",
    "train_df = pd.read_parquet(DATA_DIR / 'train.parquet')\n",
    "val_comp = pd.read_parquet(DATA_DIR / 'val_competition.parquet')\n",
    "\n",
    "COMP_DIR = find_file('test.csv')\n",
    "test_df = pd.read_csv(COMP_DIR / 'test.csv') if COMP_DIR else None\n",
    "\n",
    "gold_df = train_df[train_df['quality'] == 'gold'].reset_index(drop=True)\n",
    "print(f'Gold training: {len(gold_df)}')\n",
    "print(f'Competition val: {len(val_comp)}')\n",
    "if test_df is not None:\n",
    "    print(f'Test samples: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NLLB Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLLB_MODEL = 'phucthaiv02/akkadian-nllb-2'\n",
    "\n",
    "print(f'Loading {NLLB_MODEL}...')\n",
    "t0 = time.time()\n",
    "\n",
    "nllb_tokenizer = AutoTokenizer.from_pretrained(NLLB_MODEL)\n",
    "nllb_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    NLLB_MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto',\n",
    ")\n",
    "nllb_model.eval()\n",
    "\n",
    "n_params = sum(p.numel() for p in nllb_model.parameters()) / 1e9\n",
    "print(f'Loaded in {time.time()-t0:.0f}s ({n_params:.1f}B params)')\n",
    "print(f'GPU memory: {torch.cuda.memory_allocated()/1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nllb_translate_batch(texts, tokenizer, model, batch_size=8,\n",
    "                         max_source=512, max_target=512, num_beams=4):\n",
    "    \"\"\"Translate a list of texts using NLLB.\"\"\"\n",
    "    all_preds = []\n",
    "    n_batches = math.ceil(len(texts) / batch_size)\n",
    "    eng_id = tokenizer.convert_tokens_to_ids('eng_Latn')\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            batch, max_length=max_source, truncation=True,\n",
    "            padding=True, return_tensors='pt'\n",
    "        ).to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = model.generate(\n",
    "                **enc,\n",
    "                max_length=max_target,\n",
    "                num_beams=num_beams,\n",
    "                forced_bos_token_id=eng_id,\n",
    "                length_penalty=1.0,\n",
    "                early_stopping=True,\n",
    "            )\n",
    "        decoded = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "        all_preds.extend(decoded)\n",
    "        \n",
    "        bn = i // batch_size + 1\n",
    "        if bn % 100 == 0 or bn == n_batches:\n",
    "            elapsed = time.time() - t0\n",
    "            rate = len(all_preds) / elapsed\n",
    "            eta = (len(texts) - len(all_preds)) / rate if rate > 0 else 0\n",
    "            print(f'  Batch {bn}/{n_batches} | {len(all_preds)}/{len(texts)} done | '\n",
    "                  f'{rate:.1f} samples/s | ETA {eta/60:.0f}min')\n",
    "    \n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot Eval on Competition Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_trans = val_comp['transliteration'].tolist()\n",
    "comp_refs = val_comp['translation'].tolist()\n",
    "\n",
    "print(f'NLLB zero-shot on competition val ({len(comp_trans)} samples)...')\n",
    "nllb_comp_preds = nllb_translate_batch(comp_trans, nllb_tokenizer, nllb_model, batch_size=4)\n",
    "\n",
    "b = BLEU().corpus_score(nllb_comp_preds, [comp_refs]).score\n",
    "c = CHRF(word_order=2).corpus_score(nllb_comp_preds, [comp_refs]).score\n",
    "g = math.sqrt(max(b, 0) * max(c, 0))\n",
    "print(f'\\nNLLB zero-shot: BLEU={b:.2f}  chrF++={c:.2f}  geo_mean={g:.4f}')\n",
    "\n",
    "for j in range(min(5, len(nllb_comp_preds))):\n",
    "    print(f'\\n[{j}] Src: {comp_trans[j][:120]}...')\n",
    "    print(f'    NLLB: {nllb_comp_preds[j][:250]}')\n",
    "    print(f'    Ref:  {comp_refs[j][:250]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate NLLB Translations for All Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Generating NLLB translations for {len(gold_df)} gold samples...')\n",
    "t0 = time.time()\n",
    "\n",
    "gold_trans = gold_df['transliteration'].tolist()\n",
    "nllb_gold_preds = nllb_translate_batch(gold_trans, nllb_tokenizer, nllb_model, batch_size=8)\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f'\\nDone in {elapsed/60:.1f} min ({elapsed/len(gold_trans):.2f}s/sample)')\n",
    "\n",
    "gold_out = gold_df.copy()\n",
    "gold_out['nllb_translation'] = nllb_gold_preds\n",
    "gold_out.to_parquet('/kaggle/working/gold_with_nllb.parquet', index=False)\n",
    "print(f'Saved gold_with_nllb.parquet ({len(gold_out)} rows)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate for Competition Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_df is not None:\n",
    "    test_trans = test_df['transliteration'].tolist()\n",
    "    print(f'Generating NLLB translations for {len(test_trans)} test samples...')\n",
    "    nllb_test_preds = nllb_translate_batch(\n",
    "        test_trans, nllb_tokenizer, nllb_model, batch_size=2,\n",
    "        max_source=768, max_target=512\n",
    "    )\n",
    "    test_out = test_df.copy()\n",
    "    test_out['nllb_translation'] = nllb_test_preds\n",
    "    test_out.to_csv('/kaggle/working/test_nllb_predictions.csv', index=False)\n",
    "    \n",
    "    # Also save as a direct submission (NLLB-only baseline)\n",
    "    nllb_sub = pd.DataFrame({'id': test_df['id'], 'translation': nllb_test_preds})\n",
    "    nllb_sub.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "    print('Saved test predictions + NLLB-only submission')\n",
    "    \n",
    "    for j in range(len(nllb_test_preds)):\n",
    "        print(f'\\n[{j}] {test_trans[j][:100]}...')\n",
    "        print(f'    → {nllb_test_preds[j][:300]}')\n",
    "else:\n",
    "    print('No test.csv found — skipping test generation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Output Files ===')\n",
    "for f in Path('/kaggle/working').glob('*'):\n",
    "    if f.is_file():\n",
    "        print(f'  {f.name}  ({f.stat().st_size / 1e6:.1f} MB)')\n",
    "\n",
    "print(f'\\n=== Next Step ===')\n",
    "print('Upload gold_with_nllb.parquet as a Kaggle dataset,')\n",
    "print('then run Notebook 2 (byt5_nllb_train) to fine-tune ByT5.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}