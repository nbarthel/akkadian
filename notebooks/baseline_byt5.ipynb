{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Past Challenge - Baseline Model\n",
    "\n",
    "**Task**: Translate Akkadian transliterations to English\n",
    "\n",
    "**Approach**: Fine-tune ByT5-small (character-level T5)\n",
    "\n",
    "**Evaluation**: Geometric mean of BLEU and chrF++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers datasets sacrebleu accelerate sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "from datasets import Dataset as HFDataset\n",
    "import sacrebleu\n",
    "from sacrebleu.metrics import BLEU, CHRF\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_DIR = Path('../data/raw')\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(DATA_DIR / 'train.csv')\n",
    "test_df = pd.read_csv(DATA_DIR / 'test.csv')\n",
    "sample_sub = pd.read_csv(DATA_DIR / 'sample_submission.csv')\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"\\nTrain columns: {train_df.columns.tolist()}\")\n",
    "print(f\"Test columns: {test_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview training data\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview test data\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data statistics\n",
    "train_df['src_len'] = train_df['transliteration'].str.len()\n",
    "train_df['tgt_len'] = train_df['translation'].str.len()\n",
    "\n",
    "print(\"Source (Akkadian) length stats:\")\n",
    "print(train_df['src_len'].describe())\n",
    "print(\"\\nTarget (English) length stats:\")\n",
    "print(train_df['tgt_len'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection - ByT5 works at character level, good for special chars\n",
    "MODEL_NAME = \"google/byt5-small\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Vocab size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "# Add task prefix for T5-style models\n",
    "PREFIX = \"translate Akkadian to English: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [PREFIX + text for text in examples['transliteration']]\n",
    "    targets = examples['translation']\n",
    "    \n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    \n",
    "    labels = tokenizer(\n",
    "        targets,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    \n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(\n",
    "    train_df[['transliteration', 'translation']], \n",
    "    test_size=0.1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_data)}\")\n",
    "print(f\"Val size: {len(val_data)}\")\n",
    "\n",
    "# Convert to HuggingFace datasets\n",
    "train_dataset = HFDataset.from_pandas(train_data.reset_index(drop=True))\n",
    "val_dataset = HFDataset.from_pandas(val_data.reset_index(drop=True))\n",
    "\n",
    "# Tokenize\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=['transliteration', 'translation'])\n",
    "val_dataset = val_dataset.map(preprocess_function, batched=True, remove_columns=['transliteration', 'translation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring metrics\n",
    "bleu = BLEU()\n",
    "chrf = CHRF(word_order=2)  # chrF++\n",
    "\n",
    "def compute_metrics(predictions_and_labels):\n",
    "    preds, labels = predictions_and_labels\n",
    "    \n",
    "    # Decode predictions\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in labels (padding)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Compute metrics\n",
    "    bleu_score = bleu.corpus_score(decoded_preds, [decoded_labels]).score\n",
    "    chrf_score = chrf.corpus_score(decoded_preds, [decoded_labels]).score\n",
    "    \n",
    "    # Geometric mean (competition metric)\n",
    "    geo_mean = np.sqrt(bleu_score * chrf_score)\n",
    "    \n",
    "    return {\n",
    "        'bleu': bleu_score,\n",
    "        'chrf': chrf_score,\n",
    "        'geo_mean': geo_mean\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='../models/byt5-akkadian-baseline',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=10,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=512,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='geo_mean',\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    "    report_to='none',\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True,\n",
    "    label_pad_token_id=-100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation\n",
    "validation_results = trainer.evaluate()\n",
    "print(\"\\nValidation Results:\")\n",
    "for k, v in validation_results.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "test_inputs = [PREFIX + text for text in test_df['transliteration']]\n",
    "\n",
    "# Tokenize\n",
    "test_encodings = tokenizer(\n",
    "    test_inputs,\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='pt'\n",
    ").to(device)\n",
    "\n",
    "print(f\"Test samples: {len(test_inputs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate translations\n",
    "model.set_train_mode(False)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids=test_encodings['input_ids'],\n",
    "        attention_mask=test_encodings['attention_mask'],\n",
    "        max_length=512,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "    )\n",
    "\n",
    "# Decode\n",
    "predictions = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "# Show predictions\n",
    "for i, (src, pred) in enumerate(zip(test_df['transliteration'], predictions)):\n",
    "    print(f\"\\n--- Sample {i} ---\")\n",
    "    print(f\"Source: {src[:100]}...\")\n",
    "    print(f\"Translation: {pred[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'translation': predictions\n",
    "})\n",
    "\n",
    "# Save\n",
    "submission.to_csv('../submissions/baseline_byt5.csv', index=False)\n",
    "print(\"Submission saved!\")\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with sample submission format\n",
    "print(\"Sample submission format:\")\n",
    "print(sample_sub.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model.save_pretrained('../models/byt5-akkadian-baseline/final')\n",
    "tokenizer.save_pretrained('../models/byt5-akkadian-baseline/final')\n",
    "print(\"Model saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
